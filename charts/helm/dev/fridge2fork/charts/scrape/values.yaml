# Scrape Service Configuration
image:
  repository: ggorockee/fridge2fork-scrape
  tag: sha-8992dffe
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000
  targetPort: 8000

resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "200m"

# Job configuration
activeDeadlineSeconds: 7200  # 2시간 타임아웃
backoffLimit: 3  # 최대 재시도 횟수
restartPolicy: OnFailure
ttlSecondsAfterFinished: 2592000  # 한 달 (30일 * 24시간 * 60분 * 60초)
jobDisabled: true  # scrape job 비활성화

# Job 재생성 설정
jobRecreate:
  enabled: true  # job 재생성 활성화
  deletePolicy: "before-hook-creation"  # 기존 job 삭제 정책
  forceDelete: true  # 강제 삭제

# ServiceAccount configuration
serviceAccount:
  create: true
  annotations: {}
  name: ""

# Pod security context
podSecurityContext:
  fsGroup: 2000

# Container security context
securityContext:
  capabilities:
    drop:
    - ALL
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 1000

# Pod annotations
podAnnotations: {}

# Image pull secrets
imagePullSecrets: []

# Node selector
nodeSelector: {}

# Tolerations
tolerations: []

# Affinity
affinity: {}

# Autoscaling
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80

# Health check configuration (disabled by default)
healthCheck:
  enabled: false
  livenessProbe:
    httpGet:
      path: /health
      port: http
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3
  readinessProbe:
    httpGet:
      path: /ready
      port: http
    initialDelaySeconds: 5
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3

# Environment variables from secrets
# REQUIRED: This secret must exist before deploying the chart
# The secret should contain database connection information
envFrom:
  - secretRef:
      name: fridge2fork-db-credentials  # Must exist in the namespace

# ConfigMap configuration
configMap:
  enabled: true
  config:
    # 크롤링 설정 (25만개 수집용)
    TARGET_RECIPE_COUNT: "250000"
    CONCURRENT_REQUESTS: "5"
    BATCH_SIZE: "100"
    REQUEST_DELAY: "1"
    BATCH_DELAY: "5"
    
    # 로깅 설정
    LOG_LEVEL: "INFO"
    
    # 모니터링 설정
    PROGRESS_INTERVAL: "1000"
    MEMORY_CHECK_INTERVAL: "10000"
    
    # 메모리 최적화 설정
    CHUNK_SIZE: "1000"
    CHUNK_DELAY: "30"

# Migration Job Configuration
migration:
  enabled: true  # migration job 활성화

  # Job 재생성을 위한 설정
  jobSuffix: ""  # 비어있으면 현재 시각으로 자동 생성 (예: 20240128-143022)

  # Job 기본 설정
  restartPolicy: OnFailure
  activeDeadlineSeconds: 21600  # 6시간 타임아웃 (대용량 CSV 처리 고려)
  backoffLimit: 3  # 최대 재시도 횟수
  ttlSecondsAfterFinished: 86400  # 1일 후 자동 삭제

  # Helm Hook 설정 (선택사항)
  helm:
    hook:
      enabled: true  # Hook 사용 여부
      type: "pre-install,pre-upgrade"  # Hook 타입
      weight: "-10"  # Hook 실행 순서 (-10이 먼저 실행)
      deletePolicy: "before-hook-creation,hook-succeeded"  # Hook 삭제 정책

  # 마이그레이션 실행 방식
  useMainScript: true  # true: main.py 사용, false: scripts/migrate_csv_data.py 직접 사용
  showStats: true  # 마이그레이션 완료 후 통계 출력 여부

  # CSV 마이그레이션 설정
  enableCsvMigration: false  # CSV 마이그레이션 활성화 (기본값: false)
  chunkSize: 500  # 배치 처리 크기 (메모리 사용량과 처리 속도 균형)
  maxRecords: null  # 처리할 최대 레코드 수 (null이면 전체, 테스트시 1000 등)

  # Alembic (데이터베이스 스키마) 설정
  alembic:
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "200m"

    # Alembic 관련 환경변수
    config:
      LOG_LEVEL: "INFO"
      ALEMBIC_CONFIG: "alembic.ini"  # Alembic 설정 파일 경로

  # CSV 마이그레이션 설정
  csv:
    resources:
      requests:
        memory: "512Mi"  # CSV 처리를 위한 메모리
        cpu: "200m"
      limits:
        memory: "2Gi"    # 대용량 CSV 처리 고려
        cpu: "500m"

    # CSV 마이그레이션 관련 환경변수
    config:
      LOG_LEVEL: "INFO"
      CHUNK_SIZE: "500"      # 배치 처리 크기
      CHUNK_DELAY: "5"       # 배치 간 대기 시간 (초)
      MAX_RECORDS: ""        # 빈 문자열이면 전체 처리

      # Python 최적화 설정
      PYTHONPATH: "/app"
      PYTHONUNBUFFERED: "1"

      # 메모리 최적화
      MEMORY_CHECK_INTERVAL: "1000"  # 메모리 체크 간격
      PROGRESS_INTERVAL: "100"       # 진행률 출력 간격

  # CSV 데이터 볼륨 설정
  csvVolume:
    # 기본값: emptyDir (임시 스토리지)
    # emptyDir: {}
    
    # 또는 다른 볼륨 타입 사용 가능
    # persistentVolumeClaim:
    #   claimName: fridge2fork-csv-data
    # configMap:
    #   name: recipe-csv-data
    # hostPath:
    #   path: /data/csv

  # CSV 데이터 PVC 자동 생성 (선택사항)
  createCsvPvc: false
  csvPvc:
    size: "1Gi"
    storageClassName: ""  # 기본 스토리지 클래스 사용

  # 볼륨 설정 (외부 CSV 파일 사용시) - 하위 호환성 유지
  volumes: []
  # 예시: 외부 CSV 파일 사용
  # volumes:
  #   - name: csv-data
  #     configMap:
  #       name: recipe-csv-data
  #   - name: temp-storage
  #     emptyDir: {}

  volumeMounts: []
  # 예시: 외부 CSV 파일 마운트
  # volumeMounts:
  #   - name: csv-data
  #     mountPath: /app/datas
  #     readOnly: true
  #   - name: temp-storage
  #     mountPath: /tmp

# Alembic Job Configuration
alembic:
  enabled: false  # 기본적으로 비활성화
  restartPolicy: Never
  activeDeadlineSeconds: 1800  # 30분 타임아웃
  backoffLimit: 3  # 최대 재시도 횟수
  ttlSecondsAfterFinished: 3600  # 1시간 후 자동 삭제
  
  # Helm hook 설정 (선택사항)
  hook: ""  # pre-install, pre-upgrade, post-install, post-upgrade 등
  hookWeight: "-5"  # hook 실행 순서
  hookDeletePolicy: "before-hook-creation,hook-succeeded"  # hook 삭제 정책
  
  # Alembic 리소스
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "200m"
